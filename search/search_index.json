{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Introduction","text":"<p>In modern cloud computing environments, infrastructure management and deployment have become increasingly complex. To address this complexity, Infrastructure as Code (IaC) has emerged as a widely adopted practice. This guide will introduce how to apply the principles of IaC to the ACP (Alauda Container Platform) and leverage Terraform, a powerful IaC tool, to achieve automated and standardized infrastructure management.</p>"},{"location":"index.html#overview-of-acp-platform","title":"Overview of ACP Platform","text":"<p>ACP (Alauda Container Platform) is an advanced cloud platform product built on Kubernetes. It offers a rich set of cloud-native features, enabling organizations to deploy, manage, and scale their applications and services more efficiently. ACP exposes its resources through Kubernetes APIs, providing users with a unified and powerful interface for platform resource operations.</p>"},{"location":"index.html#iac-concept","title":"IaC Concept","text":"<p>Infrastructure as Code is an approach to defining, deploying, and managing infrastructure using code. It treats infrastructure configuration as software code, enabling version control, automated deployment, and consistent management. The key advantages of IaC include:</p> <ul> <li>Increased deployment speed and efficiency</li> <li>Reduced human error</li> <li>Enhanced configuration consistency and reproducibility</li> <li>Improved collaboration and version control</li> <li>Simplified infrastructure management and maintenance</li> </ul>"},{"location":"index.html#introduction-to-terraform","title":"Introduction to Terraform","text":"<p>Terraform, developed by HashiCorp, is a tool for IaC management that allows users to manage infrastructure and business applications using a declarative language. Terraform's support for a wide range of cloud service providers and its active community ecosystem make it an ideal choice for managing complex infrastructure.</p>"},{"location":"index.html#the-perfect-combination-of-acp-and-terraform","title":"The Perfect Combination of ACP and Terraform","text":"<p>As a Kubernetes-based cloud platform, ACP is naturally suited for IaC management approaches. By integrating Terraform with the ACP platform, users can easily achieve automated management and version control of ACP resources, making ACP management and maintenance more reliable and efficient.</p>"},{"location":"FQA.html","title":"FAQ","text":""},{"location":"FQA.html#why-choose-alekckubectl-as-the-provider","title":"Why choose alekc/kubectl as the Provider?","text":"<p>We recommend using the alekc/kubectl provider instead of the hashicorp/kubernetes provider. This recommendation is based on the following considerations:</p> <ul> <li> <p>Broader Compatibility: The alekc/kubectl Provider manages resources by directly executing kubectl commands. This approach supports all types of Kubernetes resources, including those provided through aggregated API servers. In contrast, the official Kubernetes Provider relies on server-side apply capabilities, which may be limited in certain situations.</p> </li> <li> <p>More Flexible Deployment Process: During the <code>terraform plan</code> phase, the official Kubernetes provider requires that the CRDs (Custom Resource Definitions) for all resources being used already exist in the target cluster. This means users cannot deploy resource CRDs and resource instances simultaneously within the same Terraform repository. The alekc/kubectl provider, however, does not need to verify the existence of CRDs during the plan phase, offering greater flexibility.</p> </li> <li> <p>Simplified Resource Management: The alekc/kubectl provider allows direct use of native Kubernetes YAML definitions to manage resources. For users familiar with Kubernetes, this can significantly reduce the learning curve and simplify the resource management process.</p> </li> <li> <p>Better Version Compatibility: Since the alekc/kubectl provider relies on the kubectl command-line tool, it typically adapts better to different versions of Kubernetes clusters, reducing the occurrence of version compatibility issues.</p> </li> </ul>"},{"location":"acp_resource_management.html","title":"ACP Resource Management","text":"<p>This section provides a detailed overview of managing ACP resources using Terraform. We offer three primary methods, each with its specific use cases and advantages. Users can choose the most suitable approach based on their requirements.</p>"},{"location":"acp_resource_management.html#using-terraform-acp-modules","title":"Using Terraform ACP Modules","text":"<p>Our company has encapsulated Terraform modules for several ACP resources. We recommend users to prioritize these modules for managing ACP resources. Using ACP Modules offers the following advantages:</p> <ul> <li>Simplified Configuration: Modules encapsulate complex resource configurations, allowing users to manage ACP resources through simple parameter settings.</li> <li>Best Practices: These modules are designed according to ACP-recommended best practices, making IaC writing elegant and efficient.</li> <li>Maintenance Support: These modules are continuously maintained and updated by Alauda Cloud, ensuring compatibility with the ACP platform.</li> </ul> <p>ACP Modules are hosted in the alauda/terraform-acp-modules repository. The README document in the repository introduces the basic usage of the modules to help users get started quickly. Additionally, the README document for each module in the repository provides detailed parameter descriptions and usage examples, allowing users to select appropriate modules based on their needs.</p>"},{"location":"acp_resource_management.html#managing-acp-resources-using-the-kubectl-provider","title":"Managing ACP Resources Using the Kubectl Provider","text":"<p>For users requiring greater flexibility, the <code>alekc/kubectl</code> provider can be used to directly manage ACP resources. This method allows users to precisely control all parameters of ACP resources and is particularly suitable for users familiar with ACP resource APIs. It serves as an effective complement, especially in scenarios not covered by our provided Terraform modules.</p> <p>If you find that certain scenarios are not covered by existing ACP modules, please feel free to contact us. We actively expand and improve ACP modules to meet more use cases.</p> <p>ACP resources are provided through Kubernetes APIs. This means we can directly use the Kubectl Provider to operate these resources, just like operating regular Kubernetes resources. The following example demonstrates how to use the <code>alekc/kubectl</code> provider to manage ACP resources:</p>"},{"location":"acp_resource_management.html#scenario-introduction","title":"Scenario Introduction","text":"<p>In this example, we assume there are two business clusters on the ACP platform:</p> <ul> <li><code>dev</code>: Cluster for the development environment</li> <li><code>prod</code>: Cluster for the production environment</li> </ul> <p>We will deploy different versions of the same application in these two clusters, with specific configurations for each environment:</p> <ul> <li>Development environment: Uses a newer image version, single replica deployment, and configures specific development environment variables</li> <li>Production environment: Uses a stable image version, multi-replica deployment, and configures specific production environment variables</li> </ul> <p>This example demonstrates how to use Terraform with ACP to manage applications across multiple clusters simultaneously, achieving environmental consistency and configuration differentiation.</p>"},{"location":"acp_resource_management.html#example-code","title":"Example Code","text":"<pre><code>terraform {\nrequired_providers {\nacp = {\nsource  = \"alekc/kubectl\"\nversion = \"~&gt; 2.0\"\n}\n}\n}\nvariable \"acp_endpoint\" {\ntype string\n}\nvariable \"acp_token\" {\ntype string\n}\nprovider acp {\nalias = \"dev\"\nhost = format(\"%s/kubernetes/dev\", trimsuffix(var.acp_endpoint, \"/\"))\ntoken = var.acp_token\nload_config_file = false\n}\nprovider acp {\nalias = \"prod\"\nhost = format(\"%s/kubernetes/prod\", trimsuffix(var.acp_endpoint, \"/\"))\ntoken = var.acp_token\nload_config_file = false\n}\n# application for dev environment\nresource \"kubectl_manifest\" \"dev_application\" {\nprovider = acp.dev\nyaml_body = &lt;&lt;YAML\napiVersion: app.k8s.io/v1beta1\nkind: Application\nmetadata:\n  name: my-app-dev\n  namespace: default\nspec:\n  assemblyPhase: Succeeded\n  componentKinds:\n    - group: apps\n      kind: Deployment\n    - group: \"\"\n      kind: Service\n  descriptor: {}\n  selector:\n    matchLabels:\n      app.cpaas.io/name: default/my-app-dev \nYAML\n}\nresource \"kubectl_manifest\" \"dev_application_deployment\" {\nprovider = acp.dev\nyaml_body = &lt;&lt;YAML\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.cpaas.io/name: default/my-app-dev\n  name: my-app-dev\n  namespace: default\nspec:\n  replicas: 1\n  selector:\n    matchLabels:\n      service.cpaas.io/name: default/my-app-dev\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.cpaas.io/name: default/my-app-dev\n        service.cpaas.io/name: default/my-app-dev\n    spec:\n      containers:\n        - image: my-app:latest\n          name: app\nYAML\n}\nresource \"kubectl_manifest\" \"dev_application_service\" {\nprovider = acp.dev\nyaml_body = &lt;&lt;YAML\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app-dev\n  namespace: default\nspec:\n  selector:\n    app.cpaas.io/name: default/my-app-dev\n  type: ClusterIP\n  ports:\n    - port: 80\n      targetPort: 80\nYAML\n}\n# application for prod environment\nresource \"kubectl_manifest\" \"prod_application\" {\nprovider = acp.prod\nyaml_body = &lt;&lt;YAML\napiVersion: app.k8s.io/v1beta1\nkind: Application\nmetadata:\n  name: my-app-prod\n  namespace: default\nspec:\n  assemblyPhase: Succeeded\n  componentKinds:\n    - group: apps\n      kind: Deployment\n    - group: \"\"\n      kind: Service\n  descriptor: {}\n  selector:\n    matchLabels:\n      app.cpaas.io/name: default/my-app-prod \nYAML\n}\nresource \"kubectl_manifest\" \"prod_application_deployment\" {\nprovider = acp.prod\nyaml_body = &lt;&lt;YAML\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    app.cpaas.io/name: default/my-app-prod\n  name: my-app-prod\n  namespace: default\nspec:\n  replicas: 3   \n  selector:\n    matchLabels:\n      service.cpaas.io/name: default/my-app-prod\n  strategy:\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 1\n    type: RollingUpdate\n  template:\n    metadata:\n      labels:\n        app.cpaas.io/name: default/my-app-prod\n        service.cpaas.io/name: default/my-app-prod\n    spec:\n      containers:\n        - image: my-app:1.23.4\n          name: app\nYAML\n}\nresource \"kubectl_manifest\" \"prod_application_service\" {\nprovider = acp.prod\nyaml_body = &lt;&lt;YAML\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-app-prod\n  namespace: default\nspec:\n  selector:\n    app.cpaas.io/name: default/my-app-prod\n  type: ClusterIP\n  ports:\n    - port: 80\n      targetPort: 80\nYAML\n}\n</code></pre> <p>The usage of Provider declarations in the example can be referred to in the introduction of Terraform and ACP Integration.</p>"},{"location":"acp_resource_management.html#encapsulating-custom-terraform-modules","title":"Encapsulating Custom Terraform Modules","text":"<p>For enterprise users with specific requirements, encapsulating custom Terraform Modules that fit the company's internal use cases is an ideal choice. This approach allows for module design completely based on the company's specific needs and best practices, providing a unified resource management standard for internal use, further improving team efficiency and reducing repetitive work.</p> <p>We suggest users fork and modify the alauda/terraform-acp-modules repository, or create a new repository referencing the structure and recommended practices of alauda/terraform-acp-modules for development. This repository not only provides implementations of existing modules but also details how to develop ACP modules in the Development document, along with important principles and suggestions to follow during development. This can help you create high-quality, easily maintainable custom ACP modules.</p> <p>If you encounter any issues or need further guidance during development, please feel free to contact our support team. We are more than happy to assist you in fully leveraging the powerful features of the ACP platform and Terraform.</p>"},{"location":"acp_terraform_integration.html","title":"Terraform and ACP Integration","text":"<p>The ACP (Alauda Container Platform) is a cloud platform product developed as an extension of Kubernetes. It exposes its resource management interfaces in the form of Kubernetes APIs. This architectural design allows ACP to seamlessly integrate with Kubernetes-related Providers in the Terraform ecosystem, enabling infrastructure-as-code management.</p>"},{"location":"acp_terraform_integration.html#configuring-the-provider","title":"Configuring the Provider","text":"<p>In your Terraform configuration file, you need to specify alekc/kubectl as the required provider. Here's an example configuration:</p> <pre><code>terraform {\nrequired_providers {\nacp = {\nsource  = \"alekc/kubectl\"\nversion = \"~&gt; 2.0\"\n}\n}\n}\n</code></pre> <p>Since ACP is a multi-cluster management platform, we recommend using the method of defining a provider with multiple aliases to define the provider, with each alias corresponding to a cluster name. This method allows you to manage resources for multiple clusters in the same Terraform configuration and improve the readability and maintainability of the configuration.</p> <pre><code>variable \"acp_endpoint\" {\ntype string\n}\nvariable \"acp_token\" {\ntype string\n}\nprovider acp {\nalias = \"global\"\nhost = format(\"%s/kubernetes/global\", trimsuffix(var.acp_endpoint, \"/\"))\ntoken = var.acp_token\nload_config_file = false\ninsecure = false # if acp doesn't have a valid https certificate, set this to true\n}\nprovider acp {\nalias = \"cluster-1\"\nhost = format(\"%s/kubernetes/cluster-1\", trimsuffix(var.acp_endpoint, \"/\"))\ntoken = var.acp_token\nload_config_file = false\ninsecure = false # if acp doesn't have a valid https certificate, set this to true\n}\n</code></pre> <p>The input parameters in the above example are explained as follows:    </p> <ul> <li><code>alias</code>: Represents the alias for different clusters. It's recommended to keep this consistent with the cluster names in the ACP platform.</li> <li><code>host</code>: The access address for the Kubernetes cluster. ACP provides a unified proxy for different business clusters. By using the ACP platform address with the <code>/kubernetes/&lt;cluster-name&gt;</code> path, you can proxy to the Kubernetes service of the corresponding business cluster. This method allows uniform access to different business clusters using the ACP user's token.</li> <li> <p><code>token</code>: The access token for the ACP platform. It can be obtained through the following steps:</p> <ul> <li>Access the ACP platform and click the Profile button in the avatar to enter the user's details page   </li> <li>Click the Add API Token button, fill in the token description as prompted, then click the Add button to generate the token   </li> </ul> </li> <li> <p><code>load_config_file</code>: Determines whether to load the local <code>kubeconfig</code> configuration. We recommend setting this to <code>false</code> and using only the <code>host</code> and <code>token</code> method to configure the cluster.</p> </li> <li><code>insecure</code>: Set this parameter to <code>false</code> if your ACP environment has a valid HTTPS certificate. Otherwise, set it to <code>true</code>.</li> </ul>"}]}